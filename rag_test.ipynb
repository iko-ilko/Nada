{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG ì‹œìŠ¤í…œ - ë·°í‹° ì½”ì¹­ AI (Hybrid: Ollama + OpenAI)\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ PDF ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ RAG(Retrieval-Augmented Generation) ì‹œìŠ¤í…œì…ë‹ˆë‹¤.\n",
    "\n",
    "## í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ (ë¹„ìš© íš¨ìœ¨ì !) â­\n",
    "- **ì„ë² ë”©**: Ollama llama3 (ë¬´ë£Œ, ë¡œì»¬)\n",
    "- **LLM**: OpenAI GPT-4o (ìœ ë£Œ, ê³ í’ˆì§ˆ, ë¹„ì „ ì§€ì›)\n",
    "\n",
    "## ì£¼ìš” ê¸°ëŠ¥\n",
    "- PDF ë¬¸ì„œ ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
    "- Ollama llama3 ì„ë² ë”© ë° Chroma DB ì €ì¥ (ë¬´ë£Œ!)\n",
    "- OpenAI GPT-4o ë¹„ì „ ëª¨ë¸ì„ ì‚¬ìš©í•œ ì´ë¯¸ì§€+í…ìŠ¤íŠ¸ ì§ˆì˜ì‘ë‹µ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.messages import HumanMessage\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import base64\n",
    "from pathlib import Path\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI API í‚¤ í™•ì¸\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "else:\n",
    "    print(\"âœ… OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"í…ìŠ¤íŠ¸ ê³µë°± ì •ë¦¬\"\"\"\n",
    "    text = re.sub(r' {2,}', ' ', text)\n",
    "    text = text.replace('\\t', ' ')\n",
    "    text = re.sub(r'\\n{3,}', '\\n\\n', text)\n",
    "    lines = [line.strip() for line in text.split('\\n')]\n",
    "    text = '\\n'.join(lines)\n",
    "    lines = [line for line in text.split('\\n') if line]\n",
    "    text = '\\n'.join(lines)\n",
    "    return text.strip()\n",
    "\n",
    "def load_documents():\n",
    "    \"\"\"PDF ë¬¸ì„œ ë¡œë“œ\"\"\"\n",
    "    loader = DirectoryLoader(\n",
    "        \"hairdata/\",\n",
    "        glob=\"**/*.pdf\",\n",
    "        loader_cls=PyPDFLoader\n",
    "    )\n",
    "    documents = loader.load()\n",
    "    for doc in documents:\n",
    "        doc.page_content = clean_text(doc.page_content)\n",
    "    return documents\n",
    "\n",
    "def chunk_doc(documents, chunk_size=500, chunk_overlap=50):\n",
    "    \"\"\"ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë¶„í• \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "        keep_separator=True\n",
    "    )\n",
    "    splits = text_splitter.split_documents(documents)\n",
    "    return splits\n",
    "\n",
    "def save_documents(documents, output_path):\n",
    "    \"\"\"ë¬¸ì„œë¥¼ JSONL í˜•ì‹ìœ¼ë¡œ ì €ì¥\"\"\"\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for i, page in enumerate(documents):\n",
    "            data = {\n",
    "                'page': i + 1,\n",
    "                'text': page.page_content,\n",
    "                'metadata': {\n",
    "                    'source': 'sample.pdf',\n",
    "                    'page': page.metadata.get('page', i)\n",
    "                }\n",
    "            }\n",
    "            f.write(json.dumps(data, ensure_ascii=False) + '\\n')\n",
    "\n",
    "def encode_image(image_path):\n",
    "    \"\"\"ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "print(\"âœ… ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ë¬¸ì„œ ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
    "\n",
    "**ì´ ì…€ì€ í•œ ë²ˆë§Œ ì‹¤í–‰í•˜ì„¸ìš”!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ë¬¸ì„œ ë¡œë“œ ì¤‘...\")\n",
    "documents = load_documents()\n",
    "print(f\"âœ… ì´ {len(documents)}ê°œì˜ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ\")\n",
    "\n",
    "print(\"\\në¬¸ì„œ ì²­í‚¹ ì¤‘...\")\n",
    "chunked_documents = chunk_doc(documents)\n",
    "print(f\"âœ… ì´ {len(chunked_documents)}ê°œì˜ ì²­í¬ ìƒì„± ì™„ë£Œ\")\n",
    "\n",
    "print(\"\\në¬¸ì„œ ì €ì¥ ì¤‘...\")\n",
    "save_documents(chunked_documents, 'tmp.jsonl')\n",
    "print(\"âœ… tmp.jsonl ì €ì¥ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ë²¡í„° ì„ë² ë”© ë° ì €ì¥ (Ollama llama3)\n",
    "\n",
    "**ì´ ì…€ë„ í•œ ë²ˆë§Œ ì‹¤í–‰í•˜ì„¸ìš”! ì´ë¯¸ ì„ë² ë”©ì´ ìˆë‹¤ë©´ 5ë²ˆ ì…€ë¡œ ë°”ë¡œ ê°€ì„¸ìš”.**\n",
    "\n",
    "**Ollamaë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ ë¬´ë£Œì…ë‹ˆë‹¤!** â­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"Ollama llama3 ì„ë² ë”© ì‹œì‘...\")\n",
    "print(f\"ì²­í¬ ê°œìˆ˜: {len(chunked_documents)}ê°œ\")\n",
    "print(\"â­ Ollama ë¡œì»¬ ëª¨ë¸ ì‚¬ìš© - ë¬´ë£Œ!\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "embedding_start = time.time()\n",
    "\n",
    "# Ollama llama3 ì„ë² ë”© ëª¨ë¸ ì‚¬ìš© (ë¡œì»¬, ë¬´ë£Œ)\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"llama3\"\n",
    ")\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunked_documents,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./chroma_db_hybrid\"\n",
    ")\n",
    "\n",
    "embedding_end = time.time()\n",
    "print(f\"âœ… Ollama llama3 ì„ë² ë”© ì™„ë£Œ: {embedding_end - embedding_start:.2f}ì´ˆ\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ (Ollama llama3)\n",
    "\n",
    "**ì„ë² ë”©ì„ ë‹¤ì‹œ í•˜ì§€ ì•Šê³  ê¸°ì¡´ ê²ƒì„ ì‚¬ìš©í•˜ë ¤ë©´ ì´ ì…€ì„ ì‹¤í–‰í•˜ì„¸ìš”!**\n",
    "\n",
    "**Ollama ë¡œì»¬ ëª¨ë¸ì´ë¯€ë¡œ ë¬´ë£Œì…ë‹ˆë‹¤!** â­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"./chroma_db_hybrid\"):\n",
    "    print(\"ê¸°ì¡´ Ollama llama3 ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì¤‘...\")\n",
    "    from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "    embeddings = OllamaEmbeddings(\n",
    "        model=\"llama3\"\n",
    "    )\n",
    "    vectorstore = Chroma(\n",
    "        persist_directory=\"./chroma_db_hybrid\",\n",
    "        embedding_function=embeddings\n",
    "    )\n",
    "    print(\"âœ… ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì™„ë£Œ\")\n",
    "else:\n",
    "    print(\"âŒ ë²¡í„°ìŠ¤í† ì–´ê°€ ì—†ìŠµë‹ˆë‹¤. 4ë²ˆ ì…€ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. RAG ì²´ì¸ ì„¤ì • (Hybrid: Ollama ì„ë² ë”© + OpenAI GPT-4o)\n",
    "\n",
    "**ë¹„ìš© íš¨ìœ¨ì ì¸ í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼:**\n",
    "- **ì„ë² ë”©**: Ollama llama3 (ë¬´ë£Œ, ë¡œì»¬)\n",
    "- **LLM/Chat**: OpenAI GPT-4o (ìœ ë£Œ, ê³ í’ˆì§ˆ, ë¹„ì „ ì§€ì›)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retriever ì„¤ì •\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3}\n",
    ")\n",
    "\n",
    "# OpenAI GPT-4o ëª¨ë¸ ì„¤ì • (ë¹„ì „ ì§€ì›)\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(f\"âœ… ì‚¬ìš© ëª¨ë¸: gpt-4o (ë¹„ì „ ì§€ì›)\")\n",
    "\n",
    "# LCEL ë°©ì‹ìœ¼ë¡œ ì²´ì¸ êµ¬ì„±\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "def create_message_with_image(inputs):\n",
    "    \"\"\"ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ë©”ì‹œì§€ë¡œ ìƒì„±\"\"\"\n",
    "    context = inputs[\"context\"]\n",
    "    question = inputs[\"question\"]\n",
    "    image_data = inputs.get(\"image\")\n",
    "\n",
    "    # í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸ êµ¬ì„± (í•œê¸€ ë‹µë³€ ê°•ì œ)\n",
    "    prompt_text = f\"\"\"ë‹¹ì‹ ì€ ë‹¤ìŒ 3ëª…ì˜ ì „ë¬¸ê°€ê°€ í†µí•©ëœ ê³ ê¸‰ ì´ë¯¸ì§€Â·ë·°í‹° ì½”ì¹­ AIì…ë‹ˆë‹¤.\n",
    "- 1. í—¤ì–´ ìŠ¤íƒ€ì¼ë¦¬ìŠ¤íŠ¸: í—¤ì–´ í˜•íƒœ, ë³¼ë¥¨, ì§ˆê°, ìŠ¤íƒ€ì¼ ë°©í–¥ì„±, ë¨¸ë¦¿ê²° ê´€ë¦¬ ë“± ë¶„ì„\n",
    "- 2. í”¼ë¶€ ê´€ë¦¬ ì „ë¬¸ê°€: í”¼ë¶€ í†¤, ìˆ˜ë¶„Â·ìœ ë¶„ ìƒíƒœ, ê²°, ì¡í‹°, ê´‘íƒ ë“± ê´€ì°°\n",
    "- 3. ì–¼êµ´ ìœ¤ê³½ ë””ìì´ë„ˆ: ëˆˆÂ·ì½”Â·ì… ë¹„ìœ¨, í„±ì„ , ë³¼ì‚´, ì´ë§ˆ ê³¡ì„ , ëŒ€ì¹­, ì…ì²´ê° ë“± ë¶„ì„\n",
    "\n",
    "[ë¶„ì„ ë°©ì‹ ì§€ì¹¨]\n",
    "1. ì‚¬ìš©ìê°€ ì œê³µí•œ ì„±ë³„, ì§ì—…, ìƒí™© ì„¤ëª…ì„ ê¸°ë°˜ìœ¼ë¡œ í•œë‹¤.\n",
    "2. ê´€ì°°ì€ ë°˜ë“œì‹œ ì‹œê°ì Â·ê°ê°ì  ìš”ì†Œ ì¤‘ ìµœì†Œ 3ê°€ì§€ ì´ìƒì„ í™œìš©í•˜ê³  ë””í…Œì¼ì„ í’ë¶€í•˜ê²Œ ë¬˜ì‚¬í•˜ì—¬, ë…ìê°€ ì¥ë©´ì„ ê·¸ë¦´ ìˆ˜ ìˆê²Œ ì‘ì„±í•œë‹¤.\n",
    "3. ë¶€ì •ì ì¸ í‘œí˜„ì„ í”¼í•˜ê³  ê°œì„  ê°€ëŠ¥ì„±ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì„œìˆ í•œë‹¤.\n",
    "4. ê°œì„  íŒì€ ì˜¤ëŠ˜ ì‹¤ì²œ ê°€ëŠ¥í•œ êµ¬ì²´ì  í–‰ë™ì´ë‚˜ ì…€í”„ ì¼€ì–´ ë°©ë²•ë§Œ í¬í•¨í•´ì•¼ í•˜ë©°, ì¶”ìƒì  ì¡°ì–¸ì€ ê¸ˆì§€ëœë‹¤.\n",
    "5. ë”°ëœ»í•˜ê³  ê²©ë ¤ì ì¸ ì–´ì¡°ë¥¼ ìœ ì§€í•˜ë©°, ê°ê´€ì ì´ë˜ ì „ë¬¸ì ìœ¼ë¡œ ì‘ì„±í•œë‹¤.\n",
    "6. ì „ë¬¸ ìš©ì–´ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ë˜ ì´í•´í•˜ê¸° ì‰¬ìš´ í‘œí˜„ìœ¼ë¡œ ì„¤ëª…í•œë‹¤.\n",
    "\n",
    "[ë¶„ì„ ì¹´í…Œê³ ë¦¬]\n",
    "1. í—¤ì–´(Hair)\n",
    "2. í”¼ë¶€(Skin)\n",
    "3. ìœ¤ê³½(Contour)\n",
    "\n",
    "[Output JSON Example]\n",
    "{{{{\n",
    "  \"Appearance_Coaching\": {{{{\n",
    "    \"Hair\": {{{{\n",
    "      \"status\": \"í—¤ì–´ì˜ í˜„ì¬ ìƒíƒœì— ëŒ€í•œ ê°„ê²°í•œ ìš”ì•½ ì„¤ëª…\",\n",
    "      \"improvement_tips\": [\n",
    "        \"ì˜¤ëŠ˜ ì‹¤ì²œ ê°€ëŠ¥í•œ êµ¬ì²´ì ì¸ í–‰ë™ 1\",\n",
    "        \"ì˜¤ëŠ˜ ì‹¤ì²œ ê°€ëŠ¥í•œ êµ¬ì²´ì ì¸ í–‰ë™ 2\"\n",
    "      ]\n",
    "    }}}},\n",
    "    \"Skin\": {{{{\n",
    "      \"status\": \"í”¼ë¶€ì˜ í˜„ì¬ ìƒíƒœì— ëŒ€í•œ ê°„ê²°í•œ ìš”ì•½ ì„¤ëª…\",\n",
    "      \"improvement_tips\": [\n",
    "        \"ì˜¤ëŠ˜ ì‹¤ì²œ ê°€ëŠ¥í•œ êµ¬ì²´ì ì¸ í–‰ë™ 1\",\n",
    "        \"ì˜¤ëŠ˜ ì‹¤ì²œ ê°€ëŠ¥í•œ êµ¬ì²´ì ì¸ í–‰ë™ 2\"\n",
    "      ]\n",
    "    }}}},\n",
    "    \"Contour\": {{{{\n",
    "      \"status\": \"ìœ¤ê³½ì˜ í˜„ì¬ ìƒíƒœì— ëŒ€í•œ ê°„ê²°í•œ ìš”ì•½ ì„¤ëª…\",\n",
    "      \"improvement_tips\": [\n",
    "        \"ì˜¤ëŠ˜ ì‹¤ì²œ ê°€ëŠ¥í•œ êµ¬ì²´ì ì¸ í–‰ë™ 1\",\n",
    "        \"ì˜¤ëŠ˜ ì‹¤ì²œ ê°€ëŠ¥í•œ êµ¬ì²´ì ì¸ í–‰ë™ 2\"\n",
    "      ]\n",
    "    }}}}\n",
    "  }}}}\n",
    "}}}}\n",
    "\n",
    "**ì¤‘ìš”: ë‹µë³€ì€ ë°˜ë“œì‹œ í•œê¸€ë¡œë§Œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤. ì˜ì–´ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.**\n",
    "ì¶œë ¥ì€ ë°˜ë“œì‹œ ìœ„ JSON í˜•ì‹ìœ¼ë¡œ í•˜ë©°, ê°œì„  íŒì€ ë°˜ë“œì‹œ ì˜¤ëŠ˜ ì‹¤ì²œ ê°€ëŠ¥í•œ êµ¬ì²´ì  í–‰ë™ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.\n",
    "\n",
    "[ì°¸ê³  ë¬¸ì„œ]\n",
    "{context}\n",
    "\n",
    "ì§ˆë¬¸: {question}\n",
    "\n",
    "ë‹µë³€:\"\"\"\n",
    "\n",
    "    # ì´ë¯¸ì§€ê°€ ìˆëŠ” ê²½ìš° ë©€í‹°ëª¨ë‹¬ ë©”ì‹œì§€ ìƒì„±\n",
    "    if image_data:\n",
    "        return [HumanMessage(\n",
    "            content=[\n",
    "                {\"type\": \"text\", \"text\": prompt_text},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"}\n",
    "                }\n",
    "            ]\n",
    "        )]\n",
    "    else:\n",
    "        # ì´ë¯¸ì§€ê°€ ì—†ëŠ” ê²½ìš° í…ìŠ¤íŠ¸ë§Œ ì „ë‹¬\n",
    "        return [HumanMessage(content=prompt_text)]\n",
    "\n",
    "qa_chain = (\n",
    "    {\n",
    "        \"context\": lambda x: format_docs(retriever.invoke(x[\"question\"])),\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "        \"image\": lambda x: x.get(\"image\")\n",
    "    }\n",
    "    | RunnableLambda(create_message_with_image)\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"âœ… RAG ì²´ì¸ ì„¤ì • ì™„ë£Œ (ì´ë¯¸ì§€ ì§€ì›)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ì§ˆì˜ì‘ë‹µ ì‹¤í–‰ (í…ìŠ¤íŠ¸ë§Œ)\n",
    "\n",
    "**ì´ë¯¸ì§€ ì—†ì´ í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©í•˜ëŠ” ê²½ìš°**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì§ˆë¬¸ì„ ì—¬ê¸°ì„œ ìˆ˜ì •í•˜ì„¸ìš”\n",
    "query = \"í™”ì‚¬í•´ë³´ì´ê³  ì‹¶ì€ë° ì—¼ìƒ‰ ì¶”ì²œí•´ì¤˜\"\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(f\"ì§ˆë¬¸: {query}\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\nRAG ì¿¼ë¦¬ ì‹œì‘... (OpenAI API í˜¸ì¶œ ì¤‘)\")\n",
    "invoke_start = time.time()\n",
    "\n",
    "result = qa_chain.invoke({\"question\": query})\n",
    "\n",
    "invoke_end = time.time()\n",
    "print(f\"âœ… RAG ì¿¼ë¦¬ ì™„ë£Œ: {invoke_end - invoke_start:.2f}ì´ˆ\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nğŸ“ ë‹µë³€:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ì§ˆì˜ì‘ë‹µ ì‹¤í–‰ (ì´ë¯¸ì§€ í¬í•¨)\n",
    "\n",
    "**ì´ë¯¸ì§€ì™€ í•¨ê»˜ ì§ˆë¬¸í•˜ëŠ” ê²½ìš°**\n",
    "\n",
    "**ì£¼ì˜: GPT-4o ë¹„ì „ ëª¨ë¸ì€ ë¹„ìš©ì´ ë” ë§ì´ ë°œìƒí•©ë‹ˆë‹¤!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ë¯¸ì§€ ê²½ë¡œì™€ ì§ˆë¬¸ì„ ìˆ˜ì •í•˜ì„¸ìš”\n",
    "image_path = \"sample_image.jpg\"\n",
    "query = \"ì´ ì‚¬ì§„ì„ ë¶„ì„í•´ì„œ ì–´ìš¸ë¦¬ëŠ” ì—¼ìƒ‰ ì¶”ì²œí•´ì¤˜\"\n",
    "\n",
    "if Path(image_path).exists():\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"ì´ë¯¸ì§€: {image_path}\")\n",
    "    print(f\"ì§ˆë¬¸: {query}\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"\\nì´ë¯¸ì§€ ì¸ì½”ë”© ì¤‘...\")\n",
    "    \n",
    "    image_base64 = encode_image(image_path)\n",
    "    print(\"âœ… ì´ë¯¸ì§€ ì¸ì½”ë”© ì™„ë£Œ\")\n",
    "    \n",
    "    print(\"\\nRAG ì¿¼ë¦¬ ì‹œì‘... (OpenAI GPT-4o Vision API í˜¸ì¶œ ì¤‘)\")\n",
    "    invoke_start = time.time()\n",
    "    \n",
    "    result = qa_chain.invoke({\n",
    "        \"question\": query,\n",
    "        \"image\": image_base64\n",
    "    })\n",
    "    \n",
    "    invoke_end = time.time()\n",
    "    print(f\"âœ… RAG ì¿¼ë¦¬ ì™„ë£Œ: {invoke_end - invoke_start:.2f}ì´ˆ\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(\"\\nğŸ“ ë‹µë³€:\")\n",
    "    print(result)\n",
    "else:\n",
    "    print(f\"âŒ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ì°¸ê³  ë¬¸ì„œ í™•ì¸ (ì„ íƒì‚¬í•­)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë§ˆì§€ë§‰ ì§ˆë¬¸ì— ëŒ€í•œ ì°¸ê³  ë¬¸ì„œ í™•ì¸\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "print(\"ğŸ“š ì°¸ê³  ë¬¸ì„œ:\")\n",
    "print(\"=\" * 50)\n",
    "for i, doc in enumerate(retrieved_docs, 1):\n",
    "    print(f\"\\n[ë¬¸ì„œ {i}]\")\n",
    "    print(doc.page_content)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì‚¬ìš© ë°©ë²• ìš”ì•½\n",
    "\n",
    "### í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ (ë¹„ìš© íš¨ìœ¨ì !) â­\n",
    "- **ì„ë² ë”©**: Ollama llama3 (ë¬´ë£Œ, ë¡œì»¬)\n",
    "- **LLM**: OpenAI GPT-4o (ìœ ë£Œ, ê³ í’ˆì§ˆ, ë¹„ì „ ì§€ì›)\n",
    "\n",
    "### ì²˜ìŒ ì‹¤í–‰í•  ë•Œ:\n",
    "1. **.env íŒŒì¼ì— OpenAI API í‚¤ ì„¤ì •** (OPENAI_API_KEY=sk-...)\n",
    "2. **Ollama llama3 ëª¨ë¸ ì„¤ì¹˜ í™•ì¸** (í„°ë¯¸ë„ì—ì„œ `ollama pull llama3`)\n",
    "3. ì…€ 1-4ë¥¼ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰ (Ollama ì„ë² ë”© ìƒì„±) â­ **ë¬´ë£Œ!**\n",
    "4. ì…€ 6ì„ ì‹¤í–‰ (RAG ì²´ì¸ ì„¤ì •)\n",
    "5. ì…€ 7ì„ ì‹¤í–‰ (í…ìŠ¤íŠ¸ë§Œ) ë˜ëŠ” ì…€ 8ì„ ì‹¤í–‰ (ì´ë¯¸ì§€ í¬í•¨) âš ï¸ **OpenAI API ë¹„ìš© ë°œìƒ**\n",
    "\n",
    "### ë‹¤ìŒë²ˆì— ì‹¤í–‰í•  ë•Œ (ì„ë² ë”© ì¬ì‚¬ìš©):\n",
    "1. ì…€ 1-2ë¥¼ ì‹¤í–‰ (ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° í•¨ìˆ˜ ë¡œë“œ)\n",
    "2. **ì…€ 5ë¥¼ ì‹¤í–‰** (ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ) â­ **4ë²ˆ ëŒ€ì‹  5ë²ˆ!**\n",
    "3. ì…€ 6ì„ ì‹¤í–‰ (RAG ì²´ì¸ ì„¤ì •)\n",
    "4. ì…€ 7 (í…ìŠ¤íŠ¸ë§Œ) ë˜ëŠ” ì…€ 8 (ì´ë¯¸ì§€ í¬í•¨) ì‹¤í–‰\n",
    "\n",
    "### ë¹„ìš© ë° ì„±ëŠ¥ íŒ:\n",
    "- **ì„ë² ë”© (Ollama)**: ì™„ì „ ë¬´ë£Œ! ë¡œì»¬ì—ì„œ ì‹¤í–‰ë¨\n",
    "- **í…ìŠ¤íŠ¸ ì§ˆì˜ (OpenAI)**: GPT-4o API ë¹„ìš©ë§Œ ë°œìƒ, ë¹„êµì  ì €ë ´\n",
    "- **ì´ë¯¸ì§€ ì§ˆì˜ (OpenAI)**: GPT-4o ë¹„ì „ ëª¨ë¸, ë¹„ìš©ì´ ë” ë†’ì§€ë§Œ ì´ë¯¸ì§€ ë¶„ì„ ê°€ëŠ¥\n",
    "- **í•œê¸€ ë‹µë³€**: í”„ë¡¬í”„íŠ¸ì— í•œê¸€ ê°•ì œ ì§€ì‹œë¬¸ ì¶”ê°€ë¨\n",
    "- ì…€ 7 ë˜ëŠ” 8ì˜ `query` ë³€ìˆ˜ë§Œ ìˆ˜ì •í•´ì„œ ì—¬ëŸ¬ ì§ˆë¬¸ì„ í…ŒìŠ¤íŠ¸í•˜ì„¸ìš”.\n",
    "\n",
    "### ê¸°ì¡´ OpenAI ì„ë² ë”©ì—ì„œ ë§ˆì´ê·¸ë ˆì´ì…˜:\n",
    "- ê¸°ì¡´ì— `./chroma_db_openai` ë””ë ‰í† ë¦¬ê°€ ìˆë‹¤ë©´, ì…€ 4ë¥¼ ì‹¤í–‰í•´ì„œ ìƒˆë¡œìš´ Ollama ì„ë² ë”©ì„ ìƒì„±í•˜ì„¸ìš”.\n",
    "- ìƒˆë¡œìš´ ì„ë² ë”©ì€ `./chroma_db_hybrid` ë””ë ‰í† ë¦¬ì— ì €ì¥ë©ë‹ˆë‹¤."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
