"""
ë¬¸ì„œ ì¸ë±ì‹± ëª¨ë“ˆ
ë¬¸ì„œë¥¼ ë¡œë“œí•˜ê³  ì²­í‚¹í•˜ì—¬ ë²¡í„° DBì— ì €ì¥í•©ë‹ˆë‹¤.

í¬í•¨ëœ í´ë˜ìŠ¤:
- DocumentLoader: PDF/TXT íŒŒì¼ ë¡œë“œ
- TextChunker: ë¬¸ì„œ ì²­í‚¹
- EmbeddingManager: ì„ë² ë”© ëª¨ë¸ ê´€ë¦¬
- VectorStoreManager: ë²¡í„° DB ê´€ë¦¬
- DocumentIndexer: ì „ì²´ ì¸ë±ì‹± ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
"""
import os
import time
from pathlib import Path
from langchain_community.document_loaders import PyPDFLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from src.config import Config


class DocumentLoader:
    """ë¬¸ì„œ ë¡œë”: PDFì™€ TXT íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""

    def __init__(self, folder_path=None):
        self.folder_path = folder_path or Config.DATA_DIR

    def load_documents(self):
        """í´ë” ì•ˆì˜ ëª¨ë“  PDFì™€ TXT íŒŒì¼ì„ ë¡œë“œ

        PDF íŒŒì¼ì€ í˜ì´ì§€ë“¤ì„ ë³‘í•©í•˜ì—¬ í•œ ë¬¸ì„œë¡œ ë§Œë“­ë‹ˆë‹¤.
        (ì²­í‚¹ ì „ì— í˜ì´ì§€ë¥¼ ë‚˜ëˆ„ë©´ ì˜ë¯¸ ìˆëŠ” ì²­í‚¹ì´ ë¶ˆê°€ëŠ¥)
        """
        documents = []

        if not os.path.exists(self.folder_path):
            print(f"âŒ í´ë” ì—†ìŒ: {self.folder_path}")
            return documents

        pdf_files = list(Path(self.folder_path).glob("*.pdf"))
        txt_files = list(Path(self.folder_path).glob("*.txt"))

        print(f"\nğŸ“„ ë¬¸ì„œ ë¡œë“œ ì¤‘... (PDF: {len(pdf_files)}, TXT: {len(txt_files)})")

        if len(pdf_files) == 0 and len(txt_files) == 0:
            print("âš ï¸  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. PDF ë˜ëŠ” TXT íŒŒì¼ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
            return documents

        # PDF ë¡œë“œ: í˜ì´ì§€ë“¤ì„ ë³‘í•©í•˜ì—¬ í•œ ë¬¸ì„œë¡œ
        for pdf_file in pdf_files:
            try:
                loader = PyPDFLoader(str(pdf_file))
                pages = loader.load()

                if pages:
                    # ëª¨ë“  í˜ì´ì§€ì˜ ë‚´ìš©ì„ í•©ì¹¨
                    merged_content = "\n\n".join([page.page_content for page in pages])

                    # ë©”íƒ€ë°ì´í„°ëŠ” ì²« í˜ì´ì§€ ê¸°ì¤€
                    merged_doc = pages[0]
                    merged_doc.page_content = merged_content
                    merged_doc.metadata["source"] = pdf_file.name
                    merged_doc.metadata["type"] = "pdf"
                    merged_doc.metadata["total_pages"] = len(pages)

                    documents.append(merged_doc)
            except Exception as e:
                print(f"   âŒ {pdf_file.name}: {e}")

        # TXT ë¡œë“œ
        for txt_file in txt_files:
            try:
                loader = TextLoader(str(txt_file), encoding="utf-8")
                docs = loader.load()

                for doc in docs:
                    doc.metadata["source"] = txt_file.name
                    doc.metadata["type"] = "txt"

                documents.extend(docs)
            except Exception as e:
                print(f"   âŒ {txt_file.name}: {e}")

        print(f"   âœ… {len(pdf_files) + len(txt_files)}ê°œ íŒŒì¼ì—ì„œ {len(documents)}ê°œ ë¬¸ì„œ ë¡œë“œ")
        return documents


class TextChunker:
    """ë¬¸ì„œ ì²­í‚¹: ê¸´ ë¬¸ì„œë¥¼ ì‘ì€ ì²­í¬ë¡œ ë¶„í• í•©ë‹ˆë‹¤."""

    def __init__(self, chunk_size=None, chunk_overlap=None):
        self.chunk_size = chunk_size or Config.CHUNK_SIZE
        self.chunk_overlap = chunk_overlap or Config.CHUNK_OVERLAP

    def chunk_documents(self, documents):
        """ë¬¸ì„œë¥¼ ì‘ì€ ì²­í¬ë¡œ ë¶„í• """
        print(f"\nâœ‚ï¸  ì²­í‚¹ ì¤‘... (í¬ê¸°: {self.chunk_size}, ì˜¤ë²„ë©: {self.chunk_overlap})")

        splitter = RecursiveCharacterTextSplitter(
            chunk_size=self.chunk_size,
            chunk_overlap=self.chunk_overlap,
            separators=["\n\n", "\n", " ", ""]
        )

        chunks = splitter.split_documents(documents)
        print(f"   âœ… {len(chunks)}ê°œ ì²­í¬ ìƒì„±")
        return chunks


class EmbeddingManager:
    """ì„ë² ë”© ê´€ë¦¬ì: ë¬¸ì„œë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""

    def __init__(self, model_name=None):
        self.model_name = model_name or Config.EMBEDDING_MODEL
        self.embeddings = None

    def get_embeddings(self):
        """ì„ë² ë”© ëª¨ë¸ ë¡œë“œ (ì²˜ìŒ ë¡œë“œì‹œë§Œ ë‹¤ìš´ë¡œë“œ)"""
        if self.embeddings is not None:
            return self.embeddings

        print(f"\nğŸ”¢ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘... ({self.model_name})")

        self.embeddings = HuggingFaceEmbeddings(model_name=self.model_name)

        print(f"   âœ… ì¤€ë¹„ ì™„ë£Œ")
        return self.embeddings


class VectorStoreManager:
    """ë²¡í„° DB ê´€ë¦¬ì: Chroma ë²¡í„° DBë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤."""

    def __init__(self, embeddings):
        self.embeddings = embeddings
        self.persist_dir = Config.CHROMA_DB_PATH
        self.collection_name = "papers"
        self.vectorstore = None

    def create_vectorstore(self, chunks):
        """ì²­í¬ë“¤ì„ ì„ë² ë”©í•˜ê³  ë²¡í„° DBì— ì €ì¥"""
        print(f"\nğŸ’¾ ë²¡í„° DB ì €ì¥ ì¤‘... ({len(chunks)}ê°œ ì²­í¬)")

        start_time = time.time()

        self.vectorstore = Chroma.from_documents(
            documents=chunks,
            embedding=self.embeddings,
            persist_directory=self.persist_dir,
            collection_name=self.collection_name
        )

        elapsed_time = time.time() - start_time
        print(f"   âœ… {elapsed_time:.2f}ì´ˆ")
        return self.vectorstore

    def load_vectorstore(self):
        """ê¸°ì¡´ ë²¡í„° DB ë¡œë“œ"""
        if not os.path.exists(self.persist_dir):
            raise FileNotFoundError(f"ë²¡í„° DBë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.persist_dir}")

        print(f"\nğŸ“‚ ë²¡í„° DB ë¡œë“œ ì¤‘...")

        self.vectorstore = Chroma(
            persist_directory=self.persist_dir,
            embedding_function=self.embeddings,
            collection_name=self.collection_name
        )

        print(f"   âœ… ë¡œë“œ ì™„ë£Œ")
        return self.vectorstore

    def get_retriever(self):
        """Retriever ë°˜í™˜ (ê²€ìƒ‰ìš©)"""
        if self.vectorstore is None:
            raise ValueError("ë²¡í„° ìŠ¤í† ì–´ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        return self.vectorstore.as_retriever(
            search_type="similarity",
            search_kwargs={"k": Config.TOP_K}
        )


class DocumentIndexer:
    """ë¬¸ì„œ ì¸ë±ì‹± ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜"""

    def __init__(self):
        self.loader = DocumentLoader()
        self.chunker = TextChunker()
        self.embedding_manager = EmbeddingManager()
        self.db_manager = None

    def build_vectorstore(self):
        """
        ë²¡í„° DB ìƒì„±
        ë¬¸ì„œ ë¡œë“œ â†’ ì²­í‚¹ â†’ ì„ë² ë”© â†’ ë²¡í„° DB ì €ì¥

        Returns:
            VectorStoreManager: ìƒì„±ëœ ë²¡í„° DB ê´€ë¦¬ì
        """
        print("\nğŸ“‘ ë¬¸ì„œ ì¸ë±ì‹± ì‹œì‘...")

        # ë¬¸ì„œ ë¡œë“œ
        documents = self.loader.load_documents()
        if len(documents) == 0:
            print("âŒ ë¬¸ì„œë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return None

        # ì²­í‚¹
        chunks = self.chunker.chunk_documents(documents)

        # ì„ë² ë”© + ë²¡í„° DB ìƒì„±
        embeddings = self.embedding_manager.get_embeddings()
        self.db_manager = VectorStoreManager(embeddings)
        self.db_manager.create_vectorstore(chunks)

        print(f"âœ… ë²¡í„° DB ìƒì„± ì™„ë£Œ")
        return self.db_manager

    def get_or_create_vectorstore(self):
        """
        ê¸°ì¡´ ë²¡í„° DBê°€ ìˆìœ¼ë©´ ë¡œë“œ, ì—†ìœ¼ë©´ ìƒì„±

        Returns:
            VectorStoreManager: ë²¡í„° DB ê´€ë¦¬ì
        """
        embeddings = self.embedding_manager.get_embeddings()
        db_manager = VectorStoreManager(embeddings)

        # ê¸°ì¡´ ë²¡í„° DB í™•ì¸
        if os.path.exists(Config.CHROMA_DB_PATH):
            print(f"\nğŸ“‚ ê¸°ì¡´ ë²¡í„° DB ë°œê²¬")
            try:
                db_manager.load_vectorstore()
                print(f"âœ… ê¸°ì¡´ ë²¡í„° DB ë¡œë“œ ì™„ë£Œ")
                return db_manager
            except Exception as e:
                print(f"âš ï¸  ë²¡í„° DB ë¡œë“œ ì‹¤íŒ¨: {e}")
                print(f"   ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤...")

        # ë²¡í„° DB ìƒì„±
        self.db_manager = db_manager
        self.build_vectorstore()
        return self.db_manager
