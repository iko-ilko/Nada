"""
RAG ì‹œìŠ¤í…œ ë©”ì¸ íŒŒì¼
ë©€í‹°ëª¨ë‹¬ ì´ë¯¸ì§€ ë¶„ì„ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
"""
from pathlib import Path
import sys
import os

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ì„¤ì •
project_root = Path(__file__).parent.absolute()
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))
os.environ['PROJECT_ROOT'] = str(project_root)

from langchain_core.runnables import RunnableLambda
from langchain_core.output_parsers import StrOutputParser

from src.config import Config
from src.indexer import DocumentIndexer, EmbeddingManager, VectorStoreManager
from src.vision import format_docs, create_multimodal_message, extract_json
from src.logger import AnalysisLogger
from src.llm import get_llm


def setup_vectorstore():
    """
    ë²¡í„° DB ì¤€ë¹„
    ê¸°ì¡´ DBê°€ ìˆìœ¼ë©´ ì¬êµ¬ì„± ì—¬ë¶€ë¥¼ ë¬»ê³ , ì—†ìœ¼ë©´ ìë™ ìƒì„±
    """
    print("=" * 60)
    print("ğŸ“š ë²¡í„° DB ì¤€ë¹„ ì¤‘...")
    print("=" * 60)

    Config.validate()

    indexer = DocumentIndexer()

    # ê¸°ì¡´ ë²¡í„° DB í™•ì¸
    if os.path.exists(Config.CHROMA_DB_PATH):
        response = input("ë²¡í„° DBë¥¼ ì¬êµ¬ì„±í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
        if response != 'y':
            # ê¸°ì¡´ DB ì‚¬ìš©
            return indexer.get_or_create_vectorstore()

    # ìƒˆë¡œ ìƒì„±
    return indexer.build_vectorstore()


def load_prompt(filename: str) -> str:
    """í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ"""
    project_root = Path(os.environ.get('PROJECT_ROOT', Path.cwd()))
    prompt_path = project_root / filename
    text = prompt_path.read_text(encoding="utf-8")
    return text


def main(
    image_url: str = "https://res.cloudinary.com/nadacloud/image/upload/v1756530521/qmfzfedoxpkt1phjn1ag.jpg",
    user_state: str = "ì–´ì œ ì €ë…ì— ë¼ë©´ì„ ë¨¹ì–´ì„œ ë¶€ì€ê²ƒê°™ì•„",
    image_detail: str = "low"
):
    """
    ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  ë¯¸ìš© ì½”ì¹­ì„ ì œê³µí•©ë‹ˆë‹¤.

    Args:
        image_url: ë¶„ì„í•  ì´ë¯¸ì§€ URL
        user_state: ì‚¬ìš©ì ìƒíƒœ ì„¤ëª…
        image_detail: ì´ë¯¸ì§€ ë””í…Œì¼ ë ˆë²¨ ("low" ë˜ëŠ” "high")
    """
    # ë²¡í„° DB ì¤€ë¹„
    setup_vectorstore()

    # ì´ë¯¸ì§€ ë””í…Œì¼ ì„¤ì • (í•„ìš”ì‹œ)
    if image_detail != Config.IMAGE_DETAIL:
        Config.IMAGE_DETAIL = image_detail

    # ë¶„ì„ íŒŒë¼ë¯¸í„°
    print(f"\nğŸ“ ë¶„ì„ ìš”ì²­:")
    print(f"   ì´ë¯¸ì§€: {image_url[:50]}...")
    print(f"   ìƒíƒœ: {user_state}")
    print(f"   ë””í…Œì¼: {image_detail}")

    # ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì¤€ë¹„
    print(f"\nğŸ”§ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì¤€ë¹„...")
    embedding_manager = EmbeddingManager()
    embeddings = embedding_manager.get_embeddings()

    db_manager = VectorStoreManager(embeddings)
    try:
        db_manager.load_vectorstore()
    except Exception as e:
        print(f"âŒ ë²¡í„° DB ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    retriever = db_manager.get_retriever()
    system_prompt = load_prompt("src/prompt/response_ko.prt")

    # LLM ì„¤ì •
    llm = get_llm()

    # LCEL ì²´ì¸ êµ¬ì„±: ê° ë‹¨ê³„ê°€ ëª…í™•í•œ ì±…ì„ì„ ê°€ì§
    chain = (
        retriever  # 1. retriever: user_stateë¡œ ë¬¸ì„œ ê²€ìƒ‰
        | RunnableLambda(format_docs)  # 2. format_docs: ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ…
        | RunnableLambda(
            lambda formatted_docs: {
                "formatted_docs": formatted_docs,
                "user_state": user_state,
                "image_url": image_url,
                "detail": image_detail,
                "system_prompt": system_prompt,
            }
        )  # 3. ë”•ì…”ë„ˆë¦¬ êµ¬ì„±
        | RunnableLambda(create_multimodal_message)  # 4. ë©”ì‹œì§€ ìƒì„±
        | llm  # 5. LLM í˜¸ì¶œ
        | StrOutputParser()  # 6. ì‘ë‹µ íŒŒì‹±
    )

    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    print(f"\n{'='*60}")
    print("ğŸš€ ë¶„ì„ ì‹œì‘")
    print(f"{'='*60}")

    try:
        # ì²´ì¸ í˜¸ì¶œ: retrieverê°€ ì²« ë‹¨ê³„ì´ë¯€ë¡œ user_state ë¬¸ìì—´ë§Œ ì „ë‹¬
        raw_response = chain.invoke(user_state)

        # JSON ì¶”ì¶œ
        analysis = extract_json(raw_response)

        # ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸° (ê²°ê³¼ ì¶œë ¥ìš©)
        search_results = retriever.invoke(user_state)

        # ê²°ê³¼ ì¶œë ¥
        print(f"\n{'='*60}")
        print("ğŸ“Š ë¶„ì„ ê²°ê³¼")
        print(f"{'='*60}")

        # ê²€ìƒ‰ëœ ë¬¸ì„œ
        print(f"\nğŸ“š ê²€ìƒ‰ëœ ë¬¸ì„œ ({len(search_results)}ê°œ):")
        papers_info = _extract_papers_info(search_results)
        if papers_info:
            for paper in papers_info:
                print(f"\n   [{paper['rank']}] {paper['source']}")
                print(f"       í˜ì´ì§€: {paper['page']} | íƒ€ì…: {paper['type']}")
                print(f"       ë¯¸ë¦¬ë³´ê¸°: {paper['content_preview'][:100]}...")
        else:
            print(f"   ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")

        # LLM ë¶„ì„ ê²°ê³¼
        print(f"\nğŸ¤– ë¶„ì„:")
        print(f"   ëª¨ë¸: {Config.LLM_MODEL}")
        print(f"   ì´ë¯¸ì§€ ë””í…Œì¼: {image_detail}")

        import json
        if isinstance(analysis, dict):
            print(json.dumps(analysis, indent=4, ensure_ascii=False))
        else:
            print(analysis)

        # ê²°ê³¼ ì €ì¥
        logger = AnalysisLogger()
        log_path = logger.save_analysis(
            image_url=image_url,
            user_state=user_state,
            search_results=search_results,
            analysis=analysis,
            image_detail=image_detail,
            model=Config.LLM_MODEL
        )

        print(f"\nğŸ’¾ ì €ì¥:")
        print(f"   {log_path}")

        print(f"\n{'='*60}")
        print(f"âœ… ì™„ë£Œ!")
        print(f"{'='*60}")

        return {
            "image_url": image_url,
            "user_state": user_state,
            "search_results": search_results,
            "papers_info": papers_info,
            "analysis": analysis,
            "model": Config.LLM_MODEL,
            "image_detail": image_detail,
            "raw_response": raw_response,
            "log_path": log_path
        }

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return None


def _extract_papers_info(search_results):
    """
    ê²€ìƒ‰ëœ ë…¼ë¬¸ë“¤ì˜ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

    Args:
        search_results: Document ê°ì²´ ë¦¬ìŠ¤íŠ¸

    Returns:
        List: ë…¼ë¬¸ ì •ë³´ ë¦¬ìŠ¤íŠ¸
    """
    papers_info = []

    for i, doc in enumerate(search_results, 1):
        paper_info = {
            "rank": i,
            "source": doc.metadata.get("source", "Unknown"),
            "type": doc.metadata.get("type", "Unknown"),
            "page": doc.metadata.get("page", "Unknown"),
            "content_preview": doc.page_content[:300] if hasattr(doc, 'page_content') else "",
            "full_content": doc.page_content if hasattr(doc, 'page_content') else "",
        }
        papers_info.append(paper_info)

    return papers_info


if __name__ == "__main__":
    # ë©€í‹°ëª¨ë‹¬ RAG ì‹¤í–‰ (ë²¡í„° DBê°€ ì—†ìœ¼ë©´ ìë™ ìƒì„±)
    main(
        image_url="https://res.cloudinary.com/nadacloud/image/upload/v1756530521/qmfzfedoxpkt1phjn1ag.jpg",
        # user_state="ë¨¸ë¦¬ìƒ‰ì„ ë°”ê¾¸ê³  ì‹¶ì€ë° ë‚˜í•œí…Œ ì–´ìš¸ë¦¬ëŠ”ê²Œ ë­˜ê¹Œ?",
        # user_state="ì–´ì œ ì €ë…ì— ë¼ë©´ì„ ë¨¹ì–´ì„œ ë¶€ì€ê²ƒê°™ì•„",
        # user_state="ì–¼êµ´ì´ ì²˜ì ¸ ë³´ì´ëŠ”ë° ê°œì„  ë°©ë²•ì´ ìˆì„ê¹Œ?",
        user_state="í”¼ë¶€ê°€ ë” ì¢‹ì•„ì§€ê³  ì‹¶ì–´.",
        image_detail="low"
    )
