"""
ë¹„ì „(Vision) ëª¨ë“ˆ
GPT-4o-miniì˜ ì´ë¯¸ì§€ ë¶„ì„ ê¸°ëŠ¥ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.
LCEL (LangChain Expression Language)ì„ ì‚¬ìš©í•œ RAG íŒŒì´í”„ë¼ì¸.
"""
import json
import re
from typing import Dict, Any, List
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableLambda
from src.config import Config


class VisionAnalyzer:
    """
    ì´ë¯¸ì§€ ë¶„ì„ì„ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤
    LCELì„ ì‚¬ìš©í•œ RAG íŒŒì´í”„ë¼ì¸ êµ¬í˜„
    """

    def __init__(self, retriever=None):
        """
        VisionAnalyzer ì´ˆê¸°í™”

        Args:
            retriever: LangChain Retriever ê°ì²´ (vectorstore.as_retriever()ë¡œ ìƒì„±)
        """
        self.llm = ChatOpenAI(
            model_name=Config.LLM_MODEL,
            temperature=Config.LLM_TEMPERATURE,
            api_key=Config.OPENAI_API_KEY
        )
        self.retriever = retriever
        self.image_detail = Config.IMAGE_DETAIL
        self.rag_chain = None
        print(f"âœ… VisionAnalyzer ì¤€ë¹„ ì™„ë£Œ (ë””í…Œì¼: {self.image_detail})")

    def _build_lcel_chain(self, system_prompt: str):
        """
        LCELì„ ì‚¬ìš©í•œ ì™„ì „í•œ RAG + ë©€í‹°ëª¨ë‹¬ LLM ì²´ì¸

        íŒŒì´í”„ë¼ì¸:
        1ï¸âƒ£ Retriever: ë¬¸ì„œ ê²€ìƒ‰
        2ï¸âƒ£ Format: ê²€ìƒ‰ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        3ï¸âƒ£ Message Creation: JSON ë©”ì‹œì§€ ê°ì²´ ìƒì„± (RunnableLambda)
        4ï¸âƒ£ LLM: ë©€í‹°ëª¨ë‹¬ ë¶„ì„ (ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸)
        5ï¸âƒ£ Parser: ë¬¸ìì—´ ì¶”ì¶œ
        """
        if self.retriever is None:
            raise ValueError("Retrieverê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        print(f"\nğŸ”— LCEL ì™„ì „ ì²´ì¸ êµ¬ì„± ì¤‘...")

        # Step 1: ì…ë ¥ ì¤€ë¹„ + RAG ì‹¤í–‰
        def prepare_and_retrieve(inputs):
            """
            ì…ë ¥ dictì—ì„œ í•„ë“œë¥¼ ì¶”ì¶œí•˜ê³  RAGë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.

            LCEL RunnableParallelì˜ ê° keyëŠ” ORIGINAL INPUTì„ ë°›ìœ¼ë¯€ë¡œ,
            ì—¬ê¸°ì„œ ëª…ì‹œì ìœ¼ë¡œ retrieverë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
            """
            query = inputs.get("query", "") if isinstance(inputs, dict) else inputs

            # RAG ì‹¤í–‰: retriever í˜¸ì¶œ
            search_results = self.retriever.invoke(query)
            formatted_docs = self._format_docs(search_results)

            return {
                "formatted_docs": formatted_docs,
                "user_state": inputs.get("user_state", "") if isinstance(inputs, dict) else "",
                "image_url": inputs.get("image_url", "") if isinstance(inputs, dict) else "",
                "detail": inputs.get("detail", "low") if isinstance(inputs, dict) else "low"
            }

        # Step 2: ë©€í‹°ëª¨ë‹¬ ë©”ì‹œì§€ ìƒì„± í•¨ìˆ˜
        def create_multimodal_messages(prepared_inputs):
            """ì´ë¯¸ì§€ + RAG ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ ë©”ì‹œì§€ ìƒì„±"""
            return [
                SystemMessage(content=system_prompt),
                HumanMessage(content=[
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": prepared_inputs["image_url"],
                            "detail": prepared_inputs["detail"]
                        }
                    },
                    {
                        "type": "text",
                        "text": self._build_final_prompt(
                            prepared_inputs["user_state"],
                            prepared_inputs["formatted_docs"],
                            prepared_inputs["image_url"]
                        )
                    }
                ])
            ]

        # Step 3: LCEL ì§ì„ í˜• íŒŒì´í”„ë¼ì¸ êµ¬ì„±
        # prepare_and_retrieve | create_multimodal_messages | llm | parser
        self.rag_chain = (
            RunnableLambda(prepare_and_retrieve)
            | RunnableLambda(create_multimodal_messages)
            | self.llm
            | StrOutputParser()
        )

        print(f"âœ… LCEL ì™„ì „ ì²´ì¸ ì¤€ë¹„ ì™„ë£Œ")
        return self.rag_chain

    def analyze_image_with_context(
        self,
        image_url: str,
        system_prompt: str,
        user_state: str,
        search_query: str = None
    ) -> Dict[str, Any]:
        """
        LCEL RAG íŒŒì´í”„ë¼ì¸ì„ í†µí•´ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.

        LCEL íŒŒì´í”„ë¼ì¸ êµ¬ì¡°:
        retriever | format_docs â†’ (documents + metadata ì „ë‹¬)
                              â†“
                    multimodal message êµ¬ì„±
                              â†“
                         LLM í˜¸ì¶œ
                              â†“
                       JSON ì¶”ì¶œ

        Args:
            image_url: ë¶„ì„í•  ì´ë¯¸ì§€ URL
            system_prompt: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ë¶„ì„ ì§€ì¹¨)
            user_state: ì‚¬ìš©ì ìƒíƒœ ì„¤ëª… (ì˜ˆ: "ì–´ì œ ë¼ë©´ ë¨¹ì–´ì„œ ë¶€ì—ˆì–´")
            search_query: RAG ê²€ìƒ‰ ì¿¼ë¦¬ (ê¸°ë³¸ê°’: user_state)

        Returns:
            Dict: ë¶„ì„ ê²°ê³¼
                {
                    "analysis": {...},  # JSON ë¶„ì„ ê²°ê³¼
                    "image_url": str,
                    "model": str,
                    "detail": str,
                    "raw_response": str,
                    "search_results": List[Document]
                }
        """
        print(f"\nğŸ” LCEL RAG íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ (ë””í…Œì¼: {self.image_detail})...")

        if search_query is None:
            search_query = user_state

        try:
            # 1ï¸âƒ£ LCEL ì²´ì¸ êµ¬ì„±
            chain = self._build_lcel_chain(system_prompt)
            print(f"\nğŸš€ LCEL ì²´ì¸ ì‹¤í–‰: {search_query}")

            # 2ï¸âƒ£ LCEL ì²´ì¸ ì‹¤í–‰ (ëª¨ë“  ë‹¨ê³„ê°€ í•˜ë‚˜ì˜ invoke í˜¸ì¶œë¡œ ì²˜ë¦¬)
            raw_response = chain.invoke({
                "user_state": user_state,
                "image_url": image_url,
                "detail": self.image_detail,
                "query": search_query  # retriever ì…ë ¥
            })

            print(f"âœ… LCEL ì²´ì¸ ì‹¤í–‰ ì™„ë£Œ")

            # 3ï¸âƒ£ ë©”íƒ€ë°ì´í„°ìš© ê²€ìƒ‰ ê²°ê³¼ ë³„ë„ ì €ì¥
            search_results = self.retriever.invoke(search_query)
            print(f"   {len(search_results)}ê°œ ë¬¸ì„œ ê²€ìƒ‰ë¨")

            # 4ï¸âƒ£ JSON ì¶”ì¶œ
            print(f"\nğŸ“‹ JSON ì¶”ì¶œ ì¤‘...")
            analysis = self._extract_json(raw_response)

            result = {
                "analysis": analysis,
                "image_url": image_url,
                "model": Config.LLM_MODEL,
                "detail": self.image_detail,
                "raw_response": raw_response,
                "search_results": search_results
            }

            print(f"âœ… LCEL RAG íŒŒì´í”„ë¼ì¸ ì™„ë£Œ")
            return result

        except Exception as e:
            print(f"âŒ ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            raise

    def _build_final_prompt(self, user_state: str, formatted_docs: str, image_url: str) -> str:
        """ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        prompt = f"""ì´ë¯¸ì§€ ë¶„ì„ ìš”ì²­

ì‚¬ìš©ì ìƒíƒœ: {user_state}

ê²€ìƒ‰ëœ ê´€ë ¨ ë¬¸ì„œ:
{formatted_docs}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."""

        return prompt

    def _format_docs(self, docs: List) -> str:
        """ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…"""
        if not docs:
            return "ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤."

        formatted = []
        for i, doc in enumerate(docs, 1):
            source = doc.metadata.get("source", "Unknown")
            content = doc.page_content[:200] if hasattr(doc, 'page_content') else str(doc)[:200]
            formatted.append(f"{i}. {source}\n   ë‚´ìš©: {content}...")

        return "\n".join(formatted)

    def change_detail_level(self, new_detail: str) -> None:
        """
        ì´ë¯¸ì§€ ë””í…Œì¼ ë ˆë²¨ ë³€ê²½

        Args:
            new_detail: "low" ë˜ëŠ” "high"

        Raises:
            ValueError: ìœ íš¨í•˜ì§€ ì•Šì€ ë””í…Œì¼ ë ˆë²¨
        """
        valid_options = ["low", "high"]
        if new_detail not in valid_options:
            raise ValueError(
                f"ë””í…Œì¼ ë ˆë²¨ì€ {valid_options} ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤. "
                f"ë°›ì€ ê°’: {new_detail}"
            )

        self.image_detail = new_detail
        print(f"âœ… ì´ë¯¸ì§€ ë””í…Œì¼ ë ˆë²¨ ë³€ê²½: {new_detail}")


    def _extract_json(self, content: str) -> Dict[str, Any]:
        """
        ì‘ë‹µì—ì„œ JSONì„ ì¶”ì¶œí•©ë‹ˆë‹¤.

        Args:
            content: LLM ì‘ë‹µ í…ìŠ¤íŠ¸

        Returns:
            Dict: ì¶”ì¶œëœ JSON ê°ì²´

        Raises:
            ValueError: JSON ì¶”ì¶œ ì‹¤íŒ¨
        """
        if not content:
            raise ValueError("ë¹ˆ ì‘ë‹µì…ë‹ˆë‹¤")

        # 1. ì „ì²´ í…ìŠ¤íŠ¸ê°€ JSONì¸ì§€ í™•ì¸
        try:
            return json.loads(content.strip())
        except json.JSONDecodeError:
            pass

        # 2. { ... } íŒ¨í„´ìœ¼ë¡œ JSON ê°ì²´ ì°¾ê¸°
        brace_pattern = r'\{.*\}'
        matches = re.findall(brace_pattern, content, re.DOTALL)

        for match in matches:
            try:
                return json.loads(match.strip())
            except json.JSONDecodeError:
                continue

        # 3. ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ ê²½ê³ 
        print(f"âš ï¸  JSON ì¶”ì¶œ ì‹¤íŒ¨. ì›ë³¸ ì‘ë‹µ ë°˜í™˜")
        return {
            "raw_response": content,
            "error": "JSON ì¶”ì¶œ ì‹¤íŒ¨",
            "parsing_attempted": True
        }
