# RAG (Retrieval-Augmented Generation) í•™ìŠµ ë° êµ¬í˜„ í”Œë¡œìš°

**ì‘ì„±ì¼**: 2025-11-11
**ëª©í‘œ**: 2ì‹œê°„ ë‚´ì— RAG íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ë° ë…¼ë¬¸ ë°ì´í„° ê²€ìƒ‰ ì‹œìŠ¤í…œ êµ¬í˜„

---

## ğŸ“š ëª©ì°¨
1. [RAG ê°œìš”](#rag-ê°œìš”)
2. [í•µì‹¬ ê°œë…](#í•µì‹¬-ê°œë…)
3. [ê¸°ìˆ  ìŠ¤íƒ](#ê¸°ìˆ -ìŠ¤íƒ)
4. [RAG íŒŒì´í”„ë¼ì¸ êµ¬ì¡°](#rag-íŒŒì´í”„ë¼ì¸-êµ¬ì¡°)
5. [êµ¬í˜„ ë‹¨ê³„ë³„ ê°€ì´ë“œ](#êµ¬í˜„-ë‹¨ê³„ë³„-ê°€ì´ë“œ)
6. [ì‹¤ì œ ì½”ë“œ ì˜ˆì œ](#ì‹¤ì œ-ì½”ë“œ-ì˜ˆì œ)
7. [ìµœì í™” ì „ëµ](#ìµœì í™”-ì „ëµ)
8. [2ì‹œê°„ êµ¬í˜„ ë¡œë“œë§µ](#2ì‹œê°„-êµ¬í˜„-ë¡œë“œë§µ)

---

## RAG ê°œìš”

### ğŸ“Œ RAGë€?
**Retrieval-Augmented Generation(RAG)** ëŠ” ìƒì„±í˜• AIê°€ ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•œ í›„, ê·¸ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤.

### ğŸ¯ RAGì˜ ì¥ì 
- **ìµœì‹  ì •ë³´ ì œê³µ**: í•™ìŠµ ë°ì´í„° ì´í›„ì˜ ìµœì‹  ì •ë³´ í™œìš© ê°€ëŠ¥
- **ë„ë©”ì¸ íŠ¹í™”**: íŠ¹ì • ë¶„ì•¼(ë…¼ë¬¸, ë³´ê³ ì„œ, ë‚´ë¶€ ë¬¸ì„œ ë“±) ë°ì´í„° í™œìš©
- **ì˜¤ë¥˜ ê°ì†Œ**: ìƒì„±ëœ ë‹µë³€ì˜ ì‚¬ì‹¤ì„±ê³¼ ì •í™•ë„ í–¥ìƒ
- **ì¶œì²˜ ì œê³µ**: ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ í†µí•´ ë‹µë³€ì˜ ê·¼ê±° ì œì‹œ ê°€ëŠ¥

### ë¹„êµ: ì¼ë°˜ LLM vs RAG
```
ì¼ë°˜ LLM:  ì‚¬ìš©ì ì§ˆë¬¸ â†’ LLM (í•™ìŠµëœ ì§€ì‹ìœ¼ë¡œë§Œ ë‹µë³€ ìƒì„±)

RAG:       ì‚¬ìš©ì ì§ˆë¬¸ â†’ ë²¡í„° DB ê²€ìƒ‰ â†’ ê´€ë ¨ ë¬¸ì„œ ì¶”ì¶œ
           â†’ í”„ë¡¬í”„íŠ¸ êµ¬ì„± â†’ LLM (ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ ìƒì„±)
```

---

## í•µì‹¬ ê°œë…

### 1ï¸âƒ£ **ì„ë² ë”©(Embedding)**
í…ìŠ¤íŠ¸, ì´ë¯¸ì§€ ë“±ì˜ ë°ì´í„°ë¥¼ ê³ ì°¨ì›ì˜ ë²¡í„°(ìˆ«ì ë°°ì—´)ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •

**íŠ¹ì§•**:
- ì˜ë¯¸ê°€ ìœ ì‚¬í•œ ë°ì´í„°ëŠ” ë²¡í„° ê³µê°„ì—ì„œë„ ê°€ê¹ê²Œ ìœ„ì¹˜
- ë²¡í„° ê°„ ê±°ë¦¬ë¥¼ í†µí•´ ìœ ì‚¬ë„ ê³„ì‚° ê°€ëŠ¥
- ìˆ˜í•™ì  ì—°ì‚°ì´ ë¹ ë¥´ê³  íš¨ìœ¨ì 

**ì„ë² ë”© ëª¨ë¸ ì„ íƒ (2025ë…„ ìµœì‹ )**:
- **OpenAI**: `text-embedding-3-small`, `text-embedding-3-large` (ìµœì‹ , ìœ ë£Œ)
- **ì˜¤í”ˆì†ŒìŠ¤**: `all-MiniLM-L6-v2`, `multilingual-e5-large` (ë¬´ë£Œ, ë¡œì»¬)
- **í•œêµ­ì–´ íŠ¹í™”**: `KoSimCSE`, `ko-e5` (í•œêµ­ì–´ ë…¼ë¬¸ ìµœì í™”)

### 2ï¸âƒ£ **ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤(Vector DB)**
ì„ë² ë”©ëœ ë²¡í„°ë¥¼ ì €ì¥í•˜ê³  ë¹ ë¥´ê²Œ ê²€ìƒ‰í•  ìˆ˜ ìˆëŠ” ë°ì´í„°ë² ì´ìŠ¤

**ì£¼ìš” ì„ íƒì§€**:
- **Chroma**: ë¡œì»¬/ê²½ëŸ‰, ì„¤ì • ê°„ë‹¨, í•™ìŠµìš© ìµœì  â­ ì¶”ì²œ
- **FAISS**: ë©”ëª¨ë¦¬ ê¸°ë°˜, ì´ˆê³ ì†, ëŒ€ê·œëª¨ ë°ì´í„°ì…‹
- **Pinecone**: í´ë¼ìš°ë“œ ê¸°ë°˜, ê³ ê¸‰ ê¸°ëŠ¥, ìœ ë£Œ
- **Milvus**: ì˜¤í”ˆì†ŒìŠ¤, í”„ë¡œë•ì…˜ê¸‰, ì„¤ì • ë³µì¡
- **PostgreSQL + pgvector**: ê¸°ì¡´ DB í™œìš©

### 3ï¸âƒ£ **ì²­í‚¹(Chunking)**
ê¸´ ë¬¸ì„œë¥¼ ì‘ì€ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ëŠ” ê³¼ì •

**ì „ëµ**:
- **ê³ ì • í¬ê¸° ì²­í‚¹**: 200-500 í† í° ë‹¨ìœ„ (ê¸°ë³¸)
- **ì¬ê·€ì  ì²­í‚¹**: ê³„ì¸µ êµ¬ì¡° ìœ ì§€ (ë¬¸ì„œ êµ¬ì¡°ê°€ ìˆì„ ë•Œ)
- **ì˜ë¯¸ ê¸°ë°˜ ì²­í‚¹**: ë¬¸ë§¥ì„ ê³ ë ¤í•œ ë¶„í•  (ê³ ê¸‰)

**ê¶Œì¥ ì„¤ì •**:
```
- ì²­í¬ í¬ê¸°: 300-500 í† í° (ì•½ 200-400ë‹¨ì–´)
- ì˜¤ë²„ë©: 50-100 í† í° (ë¬¸ë§¥ ë³´ì¡´)
```

---

## ê¸°ìˆ  ìŠ¤íƒ

### í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬
```python
# LLM ë° RAG í”„ë ˆì„ì›Œí¬
pip install langchain langchain-community langchain-openai

# ë²¡í„° DB
pip install chromadb

# ë¬¸ì„œ ì²˜ë¦¬
pip install pypdf python-docx

# ì„ë² ë”©
pip install sentence-transformers  # ì˜¤í”ˆì†ŒìŠ¤ ì„ë² ë”© ëª¨ë¸

# ìœ í‹¸ë¦¬í‹°
pip install python-dotenv requests
```

### ì„ íƒ ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì„ íƒ)
```python
# ê³ ê¸‰ RAG
pip install langgraph  # ì—ì´ì „íŠ¸ RAG

# ë¬¸ì„œ ë¡œë”
pip install unstructured[pdf]  # PDF ê³ ê¸‰ ì²˜ë¦¬

# ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
pip install langsmith  # LangChain ëª¨ë‹ˆí„°ë§
```

---

## RAG íŒŒì´í”„ë¼ì¸ êµ¬ì¡°

### ğŸ“Š ì „ì²´ íŒŒì´í”„ë¼ì¸ ë‹¤ì´ì–´ê·¸ë¨
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RAG íŒŒì´í”„ë¼ì¸                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[ì¸ë±ì‹± ë‹¨ê³„ - í•œ ë²ˆ ìˆ˜í–‰]
1. ë¬¸ì„œ ìˆ˜ì§‘ â†’ 2. í…ìŠ¤íŠ¸ ë¶„í•  â†’ 3. ì„ë² ë”© ìƒì„± â†’ 4. ë²¡í„° DB ì €ì¥

[ì‹¤í–‰ ë‹¨ê³„ - ì‚¬ìš©ì ì¿¼ë¦¬ë§ˆë‹¤ ìˆ˜í–‰]
1. ì‚¬ìš©ì ì§ˆë¬¸ â†’ 2. ì§ˆë¬¸ ì„ë² ë”© â†’ 3. ìœ ì‚¬ë„ ê²€ìƒ‰
â†’ 4. ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ â†’ 5. í”„ë¡¬í”„íŠ¸ êµ¬ì„± â†’ 6. LLM ë‹µë³€ ìƒì„±

[ê²°ê³¼ ë°˜í™˜]
ìµœì¢… ë‹µë³€ + ì¶œì²˜ ë¬¸ì„œ ì •ë³´
```

### ë‹¨ê³„ë³„ ìƒì„¸ ì„¤ëª…

#### **[ì¸ë±ì‹± ë‹¨ê³„]**

**1ë‹¨ê³„: ë¬¸ì„œ ìˆ˜ì§‘ (Document Loading)**
```
ì…ë ¥: PDF, TXT, JSON, ì›¹ í˜ì´ì§€ ë“±
ì¶œë ¥: í…ìŠ¤íŠ¸ ë‚´ìš©
ë„êµ¬: LangChain DocumentLoaders (PyPDFLoader, TextLoader ë“±)
```

**2ë‹¨ê³„: í…ìŠ¤íŠ¸ ë¶„í•  (Text Splitting)**
```
ì…ë ¥: ì „ì²´ ë¬¸ì„œ í…ìŠ¤íŠ¸
ì²˜ë¦¬: ì²­í‚¹, ì˜¤ë²„ë© ì ìš©
ì¶œë ¥: ì‘ì€ ì²­í¬ë“¤ (Document ê°ì²´)
ë„êµ¬: RecursiveCharacterTextSplitter
```

**3ë‹¨ê³„: ì„ë² ë”© ìƒì„± (Embedding)**
```
ì…ë ¥: ê° ì²­í¬ í…ìŠ¤íŠ¸
ì²˜ë¦¬: ì‹ ê²½ë§ ëª¨ë¸ì´ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
ì¶œë ¥: ë²¡í„° ê°’ (1536 ë˜ëŠ” 384 ì°¨ì› ë“±)
ì‹œê°„: ë°ì´í„° í¬ê¸°ì— ë”°ë¼ ìˆ˜ë¶„~ìˆ˜ì‹œê°„
```

**4ë‹¨ê³„: ë²¡í„° DB ì €ì¥ (Vector Store)**
```
ì…ë ¥: ë¬¸ì„œ ì²­í¬ + ì„ë² ë”© ë²¡í„°
ì²˜ë¦¬: DBì— ì €ì¥, ì¸ë±ì‹±
ì¶œë ¥: ê²€ìƒ‰ ê°€ëŠ¥í•œ ë²¡í„° DB
```

#### **[ì‹¤í–‰ ë‹¨ê³„ - ì‚¬ìš©ì ì§ˆì˜]**

**1ë‹¨ê³„: ì‚¬ìš©ì ì§ˆë¬¸**
```
ì…ë ¥: "ë…¼ë¬¸ Xì˜ ì£¼ìš” ë°œê²¬ì€ ë¬´ì—‡ì¸ê°€?"
```

**2ë‹¨ê³„: ì§ˆë¬¸ ì„ë² ë”©**
```
ê°™ì€ ì„ë² ë”© ëª¨ë¸ ì‚¬ìš© â†’ ì§ˆë¬¸ ë²¡í„°í™”
```

**3ë‹¨ê³„: ìœ ì‚¬ë„ ê²€ìƒ‰ (Similarity Search)**
```
ì§ˆë¬¸ ë²¡í„°ì™€ DBì˜ ëª¨ë“  ë¬¸ì„œ ë²¡í„° ê°„ ê±°ë¦¬ ê³„ì‚°
ìƒìœ„ Kê°œ (ë³´í†µ 3-5ê°œ) ë¬¸ì„œ ì„ íƒ
```

**4ë‹¨ê³„: ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±**
```
ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì˜ í…ìŠ¤íŠ¸ ì—°ê²°
ë©”ëª¨ë¦¬ ì œí•œì„ ê³ ë ¤í•˜ì—¬ ìµœì í™”
```

**5ë‹¨ê³„: í”„ë¡¬í”„íŠ¸ êµ¬ì„±**
```
system_prompt + ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ + ì‚¬ìš©ì ì§ˆë¬¸
```

**6ë‹¨ê³„: LLM ë‹µë³€ ìƒì„±**
```
êµ¬ì„±ëœ í”„ë¡¬í”„íŠ¸ â†’ LLM â†’ ìµœì¢… ë‹µë³€ ìƒì„±
```

---

## êµ¬í˜„ ë‹¨ê³„ë³„ ê°€ì´ë“œ

### â±ï¸ Phase 1: í™˜ê²½ ì„¤ì • (15ë¶„)

#### 1.1 í”„ë¡œì íŠ¸ êµ¬ì¡°
```
project/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py          # ì„¤ì •
â”‚   â”œâ”€â”€ document_loader.py # ë¬¸ì„œ ë¡œë“œ
â”‚   â”œâ”€â”€ embedder.py        # ì„ë² ë”© ì²˜ë¦¬
â”‚   â”œâ”€â”€ vector_store.py    # ë²¡í„° DB ê´€ë¦¬
â”‚   â””â”€â”€ rag_chain.py       # RAG íŒŒì´í”„ë¼ì¸
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ papers/           # ë…¼ë¬¸ PDF ì €ì¥ì†Œ
â”‚   â””â”€â”€ chroma_db/        # Chroma DB ì €ì¥ì†Œ
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â””â”€â”€ main.py               # ë©”ì¸ ì‹¤í–‰ íŒŒì¼
```

#### 1.2 .env íŒŒì¼ ì„¤ì •
```bash
# LLM ì„¤ì •
OPENAI_API_KEY=your_key_here  # ë˜ëŠ” ë¡œì»¬ ëª¨ë¸ ì‚¬ìš©

# ë²¡í„° DB ì„¤ì •
CHROMA_DB_PATH=./data/chroma_db

# ì„ë² ë”© ëª¨ë¸
EMBEDDING_MODEL=all-MiniLM-L6-v2  # ë¡œì»¬ ëª¨ë¸
# EMBEDDING_MODEL=text-embedding-3-small  # OpenAI
```

---

### â±ï¸ Phase 2: ë°ì´í„° ì¤€ë¹„ (20ë¶„)

#### 2.1 ë…¼ë¬¸ ë°ì´í„° ì¤€ë¹„
```
data/papers/ ì— PDF íŒŒì¼ë“¤ ì €ì¥
- ì—°êµ¬_ë…¼ë¬¸_1.pdf
- ì—°êµ¬_ë…¼ë¬¸_2.pdf
- ...
```

#### 2.2 ë¬¸ì„œ ë¡œë” êµ¬í˜„
**ì£¼ìš” ì§€ì **:
- PDF ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (ì œëª©, ì €ì, ë‚ ì§œ)
- í…ìŠ¤íŠ¸ ì¸ì½”ë”© ë¬¸ì œ í•´ê²°
- í˜ì´ì§€ ë²ˆí˜¸ ì¶”ì 

---

### â±ï¸ Phase 3: ì„ë² ë”© ë° ë²¡í„° DB êµ¬ì¶• (30ë¶„)

#### 3.1 ì„ë² ë”© í”„ë¡œì„¸ìŠ¤
```
ë…¼ë¬¸ ë¡œë“œ â†’ í…ìŠ¤íŠ¸ ì²­í‚¹ (300 í† í° ë‹¨ìœ„)
â†’ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ â†’ ë²¡í„° ìƒì„± â†’ Chroma DB ì €ì¥
```

#### 3.2 ì£¼ìš” ì„¤ì •
- **ì²­í¬ í¬ê¸°**: 300-500 í† í°
- **ì˜¤ë²„ë©**: 50-100 í† í°
- **ë°°ì¹˜ ì²˜ë¦¬**: ëŒ€ëŸ‰ ë°ì´í„°ëŠ” ë°°ì¹˜ë¡œ ì²˜ë¦¬í•˜ì—¬ ë©”ëª¨ë¦¬ íš¨ìœ¨í™”

#### 3.3 ì„±ëŠ¥ ê³ ë ¤ì‚¬í•­
```
ì´ˆê¸° ë¹Œë“œ: 100ê°œ ë…¼ë¬¸ = ì•½ 5-10ë¶„ (ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸)
ì´í›„ ì¿¼ë¦¬: í‰ê·  1-3ì´ˆ

ë¹„ìš© ê³ ë ¤:
- ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸: ë¬´ë£Œ (ë¡œì»¬ ì‹¤í–‰)
- OpenAI API: ì•½ $0.20 per 1M í† í°
```

---

### â±ï¸ Phase 4: RAG íŒŒì´í”„ë¼ì¸ êµ¬ì¶• (25ë¶„)

#### 4.1 Retriever ì„¤ì •
```python
# ë²¡í„° DBì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
retriever = vector_store.as_retriever(
    search_type="similarity",
    search_kwargs={"k": 3}  # ìƒìœ„ 3ê°œ ë¬¸ì„œ
)
```

#### 4.2 RAG ì²´ì¸ êµ¬ì„±
```python
# LangChain RAG Chain
from langchain.chains import RetrievalQA

rag_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",  # ë˜ëŠ” "map_reduce", "refine"
    retriever=retriever,
    return_source_documents=True  # ì¶œì²˜ ë¬¸ì„œ ë°˜í™˜
)
```

#### 4.3 í”„ë¡¬í”„íŠ¸ ì»¤ìŠ¤í„°ë§ˆì´ì§•
```python
# ë…¼ë¬¸ ê²€ìƒ‰ íŠ¹í™” í”„ë¡¬í”„íŠ¸
PAPER_PROMPT = """
ë‹¹ì‹ ì€ í•™ìˆ  ë…¼ë¬¸ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì£¼ì–´ì§„ ë…¼ë¬¸ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.
ì •í™•í•˜ê³  êµ¬ì²´ì ì¸ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.

ë¬¸ì„œ:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€:
"""
```

---

### â±ï¸ Phase 5: í…ŒìŠ¤íŠ¸ ë° ìµœì í™” (20ë¶„)

#### 5.1 ê¸°ë³¸ í…ŒìŠ¤íŠ¸
```python
# ìƒ˜í”Œ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸
questions = [
    "ì´ ë…¼ë¬¸ì˜ ì£¼ìš” ê¸°ì—¬ëŠ” ë¬´ì—‡ì¸ê°€?",
    "ì—°êµ¬ ë°©ë²•ë¡ ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”",
    "ì‹¤í—˜ ê²°ê³¼ì˜ ê²°ë¡ ì€?"
]

for q in questions:
    result = rag_chain({"query": q})
    print(f"ì§ˆë¬¸: {q}")
    print(f"ë‹µë³€: {result['result']}")
    print(f"ì¶œì²˜: {result['source_documents']}")
```

#### 5.2 ì„±ëŠ¥ íŠœë‹
- ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜ ì¡°ì • (k ê°’)
- ì„ë² ë”© ëª¨ë¸ í¬ê¸° ì¡°ì •
- í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§
- ì‘ë‹µ ì‹œê°„ ì¸¡ì •

---

## ì‹¤ì œ ì½”ë“œ ì˜ˆì œ

### ì˜ˆì œ 1: ê¸°ë³¸ RAG ì‹œìŠ¤í…œ
```python
# requirements.txt
langchain
langchain-community
langchain-openai
chromadb
sentence-transformers
pypdf
python-dotenv
```

```python
# src/config.py
import os
from dotenv import load_dotenv

load_dotenv()

class Config:
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    CHROMA_DB_PATH = os.getenv("CHROMA_DB_PATH", "./data/chroma_db")
    EMBEDDING_MODEL = os.getenv("EMBEDDING_MODEL", "all-MiniLM-L6-v2")
    LLM_MODEL = os.getenv("LLM_MODEL", "gpt-3.5-turbo")
    CHUNK_SIZE = 300
    CHUNK_OVERLAP = 50
    TOP_K = 3
```

```python
# src/document_loader.py
from langchain.document_loaders import PyPDFLoader, DirectoryLoader
import os

class DocumentProcessor:
    def __init__(self, docs_path: str):
        self.docs_path = docs_path

    def load_documents(self):
        """PDF íŒŒì¼ë“¤ì„ ë¡œë“œ"""
        loader = DirectoryLoader(
            self.docs_path,
            glob="**/*.pdf",
            loader_cls=PyPDFLoader
        )
        documents = loader.load()
        print(f"ì´ {len(documents)}ê°œì˜ ë¬¸ì„œ ë¡œë“œë¨")
        return documents

    def load_and_split(self, splitter):
        """ë¬¸ì„œ ë¡œë“œ ë° ì²­í‚¹"""
        documents = self.load_documents()
        chunks = splitter.split_documents(documents)
        print(f"ì²­í‚¹ ì™„ë£Œ: {len(chunks)}ê°œì˜ ì²­í¬")
        return chunks
```

```python
# src/embedder.py
from langchain.embeddings import HuggingFaceEmbeddings
from langchain_openai import OpenAIEmbeddings
from config import Config

class EmbeddingManager:
    def __init__(self, model_name: str = None):
        self.model_name = model_name or Config.EMBEDDING_MODEL

    def get_embeddings(self):
        """ì„ë² ë”© ëª¨ë¸ ë°˜í™˜"""
        if self.model_name.startswith("text-embedding"):
            # OpenAI ëª¨ë¸
            return OpenAIEmbeddings(model=self.model_name)
        else:
            # ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸
            return HuggingFaceEmbeddings(model_name=self.model_name)
```

```python
# src/vector_store.py
from langchain.vectorstores import Chroma
from config import Config

class VectorStoreManager:
    def __init__(self, embeddings):
        self.embeddings = embeddings
        self.persist_dir = Config.CHROMA_DB_PATH

    def create_vectorstore(self, chunks):
        """ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ë° ì €ì¥"""
        vectorstore = Chroma.from_documents(
            documents=chunks,
            embedding=self.embeddings,
            persist_directory=self.persist_dir,
            collection_name="papers"
        )
        vectorstore.persist()
        print(f"ë²¡í„° ìŠ¤í† ì–´ ì €ì¥ë¨: {self.persist_dir}")
        return vectorstore

    def load_vectorstore(self):
        """ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ"""
        vectorstore = Chroma(
            persist_directory=self.persist_dir,
            embedding_function=self.embeddings,
            collection_name="papers"
        )
        return vectorstore
```

```python
# src/rag_chain.py
from langchain.chains import RetrievalQA
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from config import Config

class RAGChain:
    def __init__(self, vectorstore):
        self.vectorstore = vectorstore
        self.llm = ChatOpenAI(
            model_name=Config.LLM_MODEL,
            temperature=0.3
        )
        self.retriever = vectorstore.as_retriever(
            search_type="similarity",
            search_kwargs={"k": Config.TOP_K}
        )

    def get_rag_chain(self):
        """RAG ì²´ì¸ ìƒì„±"""
        prompt_template = """ë‹¹ì‹ ì€ í•™ìˆ  ë…¼ë¬¸ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
ì •ë³´ê°€ ì—†ìœ¼ë©´ "ë¬¸ì„œì—ì„œ ì´ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.

ë¬¸ì„œ:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€:"""

        PROMPT = PromptTemplate(
            template=prompt_template,
            input_variables=["context", "question"]
        )

        chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=self.retriever,
            return_source_documents=True,
            chain_type_kwargs={"prompt": PROMPT}
        )
        return chain

    def query(self, question: str):
        """ì§ˆë¬¸ì— ë‹µë³€"""
        chain = self.get_rag_chain()
        result = chain({"query": question})
        return {
            "answer": result["result"],
            "sources": [doc.metadata for doc in result["source_documents"]]
        }
```

```python
# main.py
from src.config import Config
from src.document_loader import DocumentProcessor
from src.embedder import EmbeddingManager
from src.vector_store import VectorStoreManager
from src.rag_chain import RAGChain
from langchain.text_splitter import RecursiveCharacterTextSplitter
import os

def main():
    # 1. ë¬¸ì„œ ë¡œë“œ ë° ì²­í‚¹
    print("=== 1ë‹¨ê³„: ë¬¸ì„œ ì²˜ë¦¬ ===")
    doc_processor = DocumentProcessor("./data/papers")
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=Config.CHUNK_SIZE,
        chunk_overlap=Config.CHUNK_OVERLAP
    )
    chunks = doc_processor.load_and_split(splitter)

    # 2. ì„ë² ë”© ë° ë²¡í„° ìŠ¤í† ì–´
    print("\n=== 2ë‹¨ê³„: ì„ë² ë”© ë° ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ===")
    embedding_manager = EmbeddingManager()
    embeddings = embedding_manager.get_embeddings()

    vector_manager = VectorStoreManager(embeddings)
    if not os.path.exists(Config.CHROMA_DB_PATH):
        vectorstore = vector_manager.create_vectorstore(chunks)
    else:
        vectorstore = vector_manager.load_vectorstore()

    # 3. RAG ì²´ì¸ ìƒì„± ë° ì§ˆì˜
    print("\n=== 3ë‹¨ê³„: RAG ì§ˆì˜ ===")
    rag_chain = RAGChain(vectorstore)

    # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸
    questions = [
        "ì´ ë…¼ë¬¸ì˜ ì£¼ìš” ê¸°ì—¬ëŠ” ë¬´ì—‡ì¸ê°€?",
        "ì—°êµ¬ ë°©ë²•ë¡ ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”",
        "ì‹¤í—˜ ê²°ê³¼ì˜ ì„±ëŠ¥ì€?"
    ]

    for question in questions:
        print(f"\nì§ˆë¬¸: {question}")
        result = rag_chain.query(question)
        print(f"ë‹µë³€: {result['answer']}")
        print(f"ì¶œì²˜: {result['sources']}")

if __name__ == "__main__":
    main()
```

---

## ìµœì í™” ì „ëµ

### ğŸš€ ê²€ìƒ‰ ì„±ëŠ¥ ìµœì í™”

#### 1. ê²€ìƒ‰ íŒŒë¼ë¯¸í„° ì¡°ì •
```python
# í˜„ì¬
retriever = vectorstore.as_retriever(
    search_type="similarity",
    search_kwargs={"k": 3}  # ìƒìœ„ 3ê°œ
)

# ìµœì í™”
retriever = vectorstore.as_retriever(
    search_type="mmr",  # Maximal Marginal Relevance
    search_kwargs={
        "k": 5,
        "fetch_k": 10,  # ì´ˆê¸° ê²€ìƒ‰ ê²°ê³¼ ìˆ˜
        "lambda_mult": 0.25  # ë‹¤ì–‘ì„± ì¡°ì ˆ
    }
)
```

#### 2. ì²­í‚¹ ì „ëµ ê°œì„ 
```python
# ê³ ì • í¬ê¸° (ê¸°ë³¸)
TextSplitter(chunk_size=300, chunk_overlap=50)

# ì¬ê·€ì  (ë§ˆí¬ë‹¤ìš´, ì½”ë“œ ë“± êµ¬ì¡°ê°€ ìˆì„ ë•Œ)
RecursiveCharacterTextSplitter(
    separators=["\n\n", "\n", " ", ""],
    chunk_size=300,
    chunk_overlap=50
)
```

#### 3. ë©”íƒ€ë°ì´í„° í™œìš©
```python
# ë¬¸ì„œ í•„í„°ë§
retriever = vectorstore.as_retriever(
    search_kwargs={
        "k": 3,
        "filter": {"author": "John Doe"}  # ì €ìë³„ í•„í„°ë§
    }
)
```

---

### ğŸ¯ ìƒì„± í’ˆì§ˆ ìµœì í™”

#### 1. í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§
```
ì¢‹ì€ í”„ë¡¬í”„íŠ¸ íŒ¨í„´:
1. ì—­í•  ì •ì˜: "ë‹¹ì‹ ì€ í•™ìˆ  ë…¼ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤"
2. ë¬¸ë§¥ ì œê³µ: ê²€ìƒ‰ëœ ë¬¸ì„œ + ë©”íƒ€ë°ì´í„°
3. ì§€ì‹œì‚¬í•­: "ì •ë³´ê°€ ì—†ìœ¼ë©´ ëª¨ë¥¸ë‹¤ê³  ë§í•˜ì„¸ìš”"
4. ì¶œë ¥ í˜•ì‹: "JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”" (í•„ìš”ì‹œ)
```

#### 2. ì²´ì¸ íƒ€ì… ì„ íƒ
```python
# "stuff": ëª¨ë“  ë¬¸ì„œë¥¼ í•œ ë²ˆì— í”„ë¡¬í”„íŠ¸ì— í¬í•¨ (ë¹ ë¦„, í† í° ì œí•œ)
# "map_reduce": ê° ë¬¸ì„œë¥¼ ê°œë³„ ì²˜ë¦¬ í›„ ê²°í•© (ëŠë¦¼, ì•ˆì •ì )
# "refine": ë°˜ë³µì ìœ¼ë¡œ ë‹µë³€ ê°œì„  (ëŠë¦¼, ê³ í’ˆì§ˆ)
```

#### 3. ì˜¨ë„(Temperature) ì¡°ì •
```python
ChatOpenAI(temperature=0.3)  # ë…¼ë¬¸ ë¶„ì„: ë‚®ìŒ (0.0-0.3)
ChatOpenAI(temperature=0.7)  # ì°½ì˜ì  ë‹µë³€: ë†’ìŒ
```

---

### ğŸ’¾ ì €ì¥ì†Œ ìµœì í™”

#### 1. Chroma DB ìµœì í™”
```python
# ì»¬ë ‰ì…˜ ëª…ì‹œ
vectorstore = Chroma(
    collection_name="papers_v1",
    persist_directory="./data/chroma_db"
)

# ì—¬ëŸ¬ ì»¬ë ‰ì…˜ ë¶„ë¦¬
# - papers_v1: ìµœì‹  ë…¼ë¬¸
# - papers_archive: ì˜¤ë˜ëœ ë…¼ë¬¸
```

#### 2. ì¸ë±ì‹± ì „ëµ
```python
# ë©”íƒ€ë°ì´í„° ì¸ë±ì‹±ìœ¼ë¡œ ì¿¼ë¦¬ ì„±ëŠ¥ í–¥ìƒ
documents = [
    Document(
        page_content=text,
        metadata={
            "source": "paper_1.pdf",
            "page": 1,
            "year": 2024,
            "category": "AI"
        }
    )
]
```

---

## 2ì‹œê°„ êµ¬í˜„ ë¡œë“œë§µ

### â±ï¸ **0:00-0:15 | í™˜ê²½ ì„¤ì • & í”„ë¡œì íŠ¸ êµ¬ì¡°**
- [ ] í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
- [ ] requirements.txt ì‘ì„± ë° pip install
- [ ] .env íŒŒì¼ ì„¤ì •
- [ ] ì†ŒìŠ¤ íŒŒì¼ ìƒì„± (config, embedder, vector_store ë“±)

### â±ï¸ **0:15-0:35 | ë°ì´í„° ì¤€ë¹„ & ë²¡í„° DB êµ¬ì¶•**
- [ ] ë…¼ë¬¸ PDF íŒŒì¼ ì¤€ë¹„ (ìµœì†Œ 3-5ê°œ)
- [ ] Document Loader êµ¬í˜„
- [ ] Text Splitter êµ¬í˜„
- [ ] ì„ë² ë”© ëª¨ë¸ ë¡œë“œ (ì˜¤í”ˆì†ŒìŠ¤ ì¶”ì²œ)
- [ ] Chroma DBì— ë¬¸ì„œ ì €ì¥

### â±ï¸ **0:35-0:55 | RAG íŒŒì´í”„ë¼ì¸ êµ¬í˜„**
- [ ] Retriever ì„¤ì •
- [ ] RAG Chain êµ¬í˜„
- [ ] í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì»¤ìŠ¤í„°ë§ˆì´ì§•
- [ ] ê¸°ë³¸ ì§ˆì˜ í…ŒìŠ¤íŠ¸

### â±ï¸ **0:55-1:10 | í…ŒìŠ¤íŠ¸ & í†µí•©**
- [ ] ìƒ˜í”Œ ì§ˆë¬¸ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
- [ ] ë‹µë³€ í’ˆì§ˆ ê²€ì¦
- [ ] ì¶œì²˜ ë¬¸ì„œ í™•ì¸
- [ ] ì„±ëŠ¥ ì¸¡ì •

### â±ï¸ **1:10-2:00 | API í†µí•© & ì›¹ ì¸í„°í˜ì´ìŠ¤**
- [ ] FastAPI ì„œë²„ êµ¬í˜„ (ë˜ëŠ” Flask)
- [ ] RAG ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„
- [ ] ê°„ë‹¨í•œ ì›¹ UI (HTML/JavaScript)
- [ ] ìµœì¢… í…ŒìŠ¤íŠ¸ ë° ë°°í¬

---

## ìµœì‹  ë™í–¥ & ê³ ê¸‰ ê¸°ë²• (2025ë…„)

### ğŸŒŸ Self-RAG
ìì²´ í‰ê°€ë¥¼ í†µí•´ ê²€ìƒ‰ ê²°ê³¼ì™€ ë‹µë³€ í’ˆì§ˆì„ ë™ì ìœ¼ë¡œ ì¡°ì •
```
ì§ˆë¬¸ â†’ ê²€ìƒ‰ â†’ ê²€ìƒ‰ ê²°ê³¼ í‰ê°€ â†’ ë¶€ì¡±í•˜ë©´ ì¬ê²€ìƒ‰ â†’ ë‹µë³€
```

### ğŸŒŸ Adaptive RAG
ì‚¬ìš©ì ì¿¼ë¦¬ ë³µì¡ë„ì— ë”°ë¼ ê²€ìƒ‰ ì „ëµì„ ì¡°ì •
```
ê°„ë‹¨í•œ ì§ˆë¬¸: ì§ì ‘ ë‹µë³€ (ë¹ ë¦„)
ë³µì¡í•œ ì§ˆë¬¸: ê¹Šì´ ìˆëŠ” ê²€ìƒ‰ + ì—¬ëŸ¬ ë‹¨ê³„ ì¶”ë¡ 
```

### ğŸŒŸ Corrective RAG
ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ê´€ë ¨ì„±ì„ ê²€ì¦í•˜ê³  í•„ìš”ì‹œ ì¬ê²€ìƒ‰
```
ê²€ìƒ‰ â†’ ê´€ë ¨ì„± í‰ê°€ â†’ ë‚®ìœ¼ë©´ ë‹¤ë¥¸ ì „ëµìœ¼ë¡œ ì¬ê²€ìƒ‰
```

---

## íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë¬¸ì œ 1: "No module named 'langchain'"
```bash
pip install --upgrade langchain langchain-community
```

### ë¬¸ì œ 2: ì„ë² ë”© ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨
```python
# ë” ì‘ì€ ëª¨ë¸ ì‚¬ìš©
from langchain.embeddings import HuggingFaceEmbeddings
embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
```

### ë¬¸ì œ 3: OpenAI API ì˜¤ë¥˜
```python
# ë¡œì»¬ ëª¨ë¸ ì‚¬ìš©ìœ¼ë¡œ ì „í™˜
from langchain.llms import Ollama
llm = Ollama(model="mistral")
```

### ë¬¸ì œ 4: ë©”ëª¨ë¦¬ ë¶€ì¡±
```python
# ë°°ì¹˜ ì²˜ë¦¬ë¡œ ë¶„í• 
def process_in_batches(documents, batch_size=10):
    for i in range(0, len(documents), batch_size):
        batch = documents[i:i+batch_size]
        # ì²˜ë¦¬
```

---

## ì°¸ê³  ìë£Œ (2025ë…„ ìµœì‹ )

### ê³µì‹ ë¬¸ì„œ
- [LangChain ê³µì‹ ë¬¸ì„œ](https://docs.langchain.com/)
- [Chroma ë²¡í„° DB](https://docs.trychroma.com/)
- [OpenAI API](https://platform.openai.com/docs/)

### í•œêµ­ì–´ íŠœí† ë¦¬ì–¼
- [WikiDocs - LangChain ì…ë¬¸ë¶€í„° ì‘ìš©ê¹Œì§€](https://wikidocs.net/book/14473)
- [í…Œë””ë…¸íŠ¸ - LangChain RAG íŒŒí—¤ì¹˜ê¸°](https://teddylee777.github.io/langchain/rag-tutorial/)
- [HelloLlama - RAG êµ¬í˜„](https://hellollama.net/)

### ì˜¤í”ˆì†ŒìŠ¤ ì„ë² ë”© ëª¨ë¸
- `all-MiniLM-L6-v2`: ê²½ëŸ‰, ë¹ ë¦„ â­ ì¶”ì²œ
- `multilingual-e5-large`: ë‹¤êµ­ì–´ ì§€ì›
- `ko-e5`: í•œêµ­ì–´ íŠ¹í™”

### ë²¡í„° DB ë¹„êµ
| ì´ë¦„ | ì¥ì  | ë‹¨ì  | ìš©ë„ |
|------|------|------|------|
| Chroma | ì„¤ì • ê°„ë‹¨, ë¡œì»¬ | ê¸°ëŠ¥ ì œí•œ | í•™ìŠµ, í”„ë¡œí† íƒ€ì… |
| FAISS | ì´ˆê³ ì† | ë©”ëª¨ë¦¬ë§Œ ì €ì¥ | í”„ë¡œë•ì…˜ ê²€ìƒ‰ |
| Pinecone | í´ë¼ìš°ë“œ ê¸°ë°˜ | ìœ ë£Œ | ì—”í„°í”„ë¼ì´ì¦ˆ |
| Milvus | ì˜¤í”ˆì†ŒìŠ¤ | ë³µì¡í•œ ì„¤ì • | ëŒ€ê·œëª¨ ë°ì´í„° |

---

## ë‹¤ìŒ ë‹¨ê³„

2ì‹œê°„ ë‚´ ê¸°ë³¸ êµ¬í˜„ í›„:

1. **ì„±ëŠ¥ ìµœì í™”**
   - ê²€ìƒ‰ ì •í™•ë„ ê°œì„ 
   - ì‘ë‹µ ì‹œê°„ ë‹¨ì¶•
   - ë©”ëª¨ë¦¬ ì‚¬ìš© ìµœì í™”

2. **ê¸°ëŠ¥ í™•ì¥**
   - ì—¬ëŸ¬ ë¬¸ì„œ íƒ€ì… ì§€ì› (PDF, DOCX, ì›¹í˜ì´ì§€)
   - ì‹¤ì‹œê°„ ë¬¸ì„œ ì—…ë°ì´íŠ¸
   - ì‚¬ìš©ì í”¼ë“œë°± ë£¨í”„

3. **í”„ë¡œë•ì…˜ ë°°í¬**
   - ì„œë²„ ë°°í¬ (AWS, GCP, Azure)
   - ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…
   - ë¹„ìš© ìµœì í™”

---

**ì‘ì„±ì**: AI í•´ì»¤í†¤ ì°¸ê°€ì
**ì—…ë°ì´íŠ¸**: 2025-11-11
**ìƒíƒœ**: ì§„í–‰ ì¤‘ âœ…
